{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0OSlSAXjEoX"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "THE DIRECTORY NAMES USED TO STORE THE DATA EXPLAIN THE STRATEGY TO CREATE THE GRAPH:\n",
        "\n",
        "PSS is the number of PAST SAME SPEAKER considered for each node (e.g. 3PSS means 3 pasts same speaker)\n",
        "PDS is the number of PAST DIFFERENT SPEAKER considered for each node (e.g. 8PDS means 8 pasts different speaker)\n",
        "Similarly there are FSS and FDS\n",
        "\n",
        "\"timestamp\" or \"reply_to\" explain how the concept of past and future comments for a specific node is defined:\n",
        "- timestamp: past and future comments (nodes) are identified by timestamp independently on the tree structure of the\n",
        "  conversation, this means that a non-main-branch comment of the conversation can be linked with comments of the main branch\n",
        "- reply_to: past and future comments (nodes) are identified by the reply_to field in the dataset, which considers\n",
        "  the structure of the conversation\n",
        "- similarity: nodes are linked dending on how similar the text is\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OK6-gwC_r1V4"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "TO DO:\n",
        "- check the results on a balanced dataset\n",
        "- check the results when going in the past follows back the tree structure of the conversation (reply_to)\n",
        "- check for models that apply explainability on GNNs\n",
        "- is there a different way to represent/preprocess text\n",
        "- check for results with different features, POS tags, emotions, number of words, number of deltas, distance from last OP utterance etc...\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ui-Wcv1NSClZ",
        "outputId": "364cae3f-733a-4ab3-ce07-21afb4290624"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5j_n1y3pKyn"
      },
      "outputs": [],
      "source": [
        "!pip install torch-geometric\n",
        "!pip3 install convokit\n",
        "!pip install transformers\n",
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEHlnUcvVR3U"
      },
      "outputs": [],
      "source": [
        "#!pip install torch-spline-conv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "NQKhDI1XDZu2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "from torch_geometric.nn import GCNConv, GATConv, SAGEConv, CGConv, SplineConv\n",
        "from torch_geometric.nn import BatchNorm, global_add_pool\n",
        "from torch.nn import Embedding, Linear, ModuleList, ReLU, Sequential\n",
        "from torch_geometric.nn import GCN, GAT, DeepGCNLayer, GENConv\n",
        "from torch_geometric.utils import degree\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, roc_auc_score, average_precision_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.tokenize import word_tokenize\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from convokit import Corpus, download\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "import emoji\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import traceback\n",
        "import sys\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "import statistics\n",
        "import copy\n",
        "import string\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import TFAutoModelForSequenceClassification\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import pipeline\n",
        "from scipy.special import softmax\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "IiDueb9wqHnK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTbXYivckWVk",
        "outputId": "fc928395-639c-41c4-f460-7e9ea6c677af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('vader_lexicon')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "7NwvSy-9bHN5"
      },
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVLB_zMZuoqR"
      },
      "outputs": [],
      "source": [
        "# Load Universal Sentence Encoder model\n",
        "universalSentenceEncoder = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-large/5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sonXaluxm6ap"
      },
      "outputs": [],
      "source": [
        "robertaModel = f\"cardiffnlp/twitter-roberta-base-emotion\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(robertaModel)\n",
        "tfmodel = TFAutoModelForSequenceClassification.from_pretrained(robertaModel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zof5Rwt7QCrh"
      },
      "outputs": [],
      "source": [
        "# see https://github.com/CornellNLP/ConvoKit/blob/master/datasets/winning-args-corpus/stats.ipynb for pre-processing\n",
        "corpus = Corpus(filename=download(\"winning-args-corpus\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XqA8ENHqS2cz"
      },
      "outputs": [],
      "source": [
        "#cIds = corpus.get_conversation_ids()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lqnBq6LMg3pO"
      },
      "outputs": [],
      "source": [
        "## START: HELPERS\n",
        "\n",
        "def featureMustBeRecomputed(cDf, featureName):\n",
        "  return featureName not in cDf.columns or alwaysCompute == True\n",
        "\n",
        "# outputs scores of emotions in this order [anger, joy, optimism, sadness]\n",
        "# (each score goes from 0 low intensity, to 1 high intensity)\n",
        "def getEmotionsScores(text):\n",
        "    em_labels = ['anger', 'joy', 'optimism', 'sadness']\n",
        "\n",
        "    encoded_input = tokenizer(text, return_tensors='tf')\n",
        "    output = tfmodel(encoded_input)\n",
        "    scores = output[0][0].numpy()\n",
        "    scores = softmax(scores).tolist()\n",
        "\n",
        "    return scores\n",
        "\n",
        "def getSpeakersDeltaFromComment(utteranceIndex):\n",
        "    numOfDeltasStringUnclean = corpus.get_utterance(utteranceIndex).meta['author_flair_text']\n",
        "    numOfDeltas = 0\n",
        "    if numOfDeltasStringUnclean != None:\n",
        "      try:\n",
        "        # cleans the string from non-digits characters and then converts to int\n",
        "        numOfDeltas = int(list(filter(str.isdigit, numOfDeltasStringUnclean))[0])\n",
        "      except:\n",
        "        return 0\n",
        "\n",
        "    return numOfDeltas\n",
        "\n",
        "def getWordsOfSentenceAsList(sentence):\n",
        "  return list(str(sentence).lower().split())\n",
        "\n",
        "def getSentenceNumOfWords(sentence):\n",
        "    if sentence == None:\n",
        "      return 0\n",
        "\n",
        "    return len(getWordsOfSentenceAsList(sentence))\n",
        "\n",
        "def numberOfcommonWordsBetweenTwoListOfWords(s1, s2):\n",
        "  commonWords = list(set(s1).intersection(s2))\n",
        "  return len(commonWords)\n",
        "\n",
        "def getStopwordsInWordsList(s1):\n",
        "  return [token for token in s1 if token in stop_words]\n",
        "\n",
        "def getContentWordsInWordsList(s1):\n",
        "  return [token for token in s1 if token not in stop_words]\n",
        "\n",
        "def getRightTimeDiff(tdiff,medianTimeDiff):\n",
        "    if tdiff == 0:\n",
        "      return medianTimeDiff\n",
        "\n",
        "    return tdiff\n",
        "\n",
        "def jaccard_similarity(doc1, doc2):\n",
        "    if doc1 == '' or doc2 == '':\n",
        "      return 0.0\n",
        "\n",
        "    if type(doc1) == list:\n",
        "      words_doc_1 = set(doc1)\n",
        "      words_doc_2 = set(doc2)\n",
        "    else:\n",
        "      # List the unique words in a document\n",
        "      words_doc_1 = set(doc1.lower().split())\n",
        "      words_doc_2 = set(doc2.lower().split())\n",
        "\n",
        "    # Find the intersection of words between documents\n",
        "    intersection = words_doc_1.intersection(words_doc_2)\n",
        "\n",
        "    # Find the union of words between documents\n",
        "    union = words_doc_1.union(words_doc_2)\n",
        "\n",
        "    # Jaccard Similarity\n",
        "    try:\n",
        "      jaccardSimilarityCoefficient = 0 if len(union) == 0 else float(len(intersection)) / len(union)\n",
        "    except:\n",
        "      print('error while calculating Jaccard similarity')\n",
        "      print('intersection: ' + str(len(intersection)))\n",
        "      print('union: ' + str(len(union)))\n",
        "      jaccardSimilarityCoefficient = 0\n",
        "    return jaccardSimilarityCoefficient\n",
        "\n",
        "## END: HELPERS OF EDGE ATTRIBUTE FUNCTIONS\n",
        "\n",
        "#------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "## START: EDGE ATTRIBUTE FUNCTIONS\n",
        "\n",
        "# computes the similarity of two sentences, by default uses the jaccard similarity\n",
        "def text_sim(cDf, edgesAsIndicesList, similarityFunction = jaccard_similarity):\n",
        "  similarityList = []\n",
        "\n",
        "  for edge in edgesAsIndicesList:\n",
        "    n1_index = edge[0]\n",
        "    n2_index = edge[1]\n",
        "\n",
        "    node1Text = cDf.loc[n1_index]['text']\n",
        "    node2Text = cDf.loc[n2_index]['text']\n",
        "\n",
        "    similarityList.append(similarityFunction(node1Text, node2Text))\n",
        "\n",
        "  return similarityList\n",
        "\n",
        "\n",
        "# computes the ratio of the deltas of the speakers of the two linked comments\n",
        "def delta_ratio(cDf, edgesAsIndicesList):\n",
        "  deltaRatioList = []\n",
        "\n",
        "  for edge in edgesAsIndicesList:\n",
        "    n1_index = edge[0]\n",
        "    n2_index = edge[1]\n",
        "\n",
        "    speaker1Deltas = getSpeakersDeltaFromComment(n1_index)\n",
        "    speaker2Deltas = getSpeakersDeltaFromComment(n2_index)\n",
        "\n",
        "    if speaker2Deltas == 0:\n",
        "      deltaRatioList.append(speaker1Deltas)\n",
        "      continue\n",
        "\n",
        "    deltaRatioList.append(speaker1Deltas / speaker2Deltas)\n",
        "\n",
        "  return deltaRatioList\n",
        "\n",
        "\n",
        "# computes the ratio between the number of words of one node compared to the linked one\n",
        "def word_len_ratio(cDf, edgesAsIndicesList):\n",
        "  deltaRatioList = []\n",
        "\n",
        "  for edge in edgesAsIndicesList:\n",
        "    n1_index = edge[0]\n",
        "    n2_index = edge[1]\n",
        "\n",
        "    node1Text = cDf.loc[n1_index].text\n",
        "    node2Text = cDf.loc[n2_index].text\n",
        "\n",
        "    numOfWords1 = getSentenceNumOfWords(node1Text)\n",
        "    numOfWords2 = getSentenceNumOfWords(node2Text)\n",
        "\n",
        "    if numOfWords2 == 0:\n",
        "      deltaRatioList.append(numOfWords1)\n",
        "      continue\n",
        "\n",
        "    deltaRatioList.append(numOfWords1 / numOfWords2)\n",
        "\n",
        "  return deltaRatioList\n",
        "\n",
        "\n",
        "# computes the difference between the timestamps of two different nodes\n",
        "def time_diff(cDf, edgesAsIndicesList):\n",
        "  timeDiffList = []\n",
        "  timeDiffListDebug = []\n",
        "  for edge in edgesAsIndicesList:\n",
        "    n1_index = edge[0]\n",
        "    n2_index = edge[1]\n",
        "    try:\n",
        "      node1Timestamp = int(cDf.loc[n1_index]['timestamp'])\n",
        "      node2Timestamp = int(cDf.loc[n2_index]['timestamp'])\n",
        "      if node1Timestamp == 0 or node2Timestamp == 0:\n",
        "        timeDiff = 0\n",
        "      else:\n",
        "        timeDiff = abs(node1Timestamp - node2Timestamp)\n",
        "    except:\n",
        "      # this can happen when timestamp is NaN and we try to convert it to int\n",
        "      timeDiff = 0\n",
        "\n",
        "    timeDiffList.append(timeDiff)\n",
        "    timeDiffListDebug.append([n1_index, n2_index, timeDiff])\n",
        "\n",
        "  timeDiffListOriginal = copy.deepcopy(timeDiffList)\n",
        "  # for all values linked to the first node (which doesn't have a timestamp) set the distance as the median value of the sorted list\n",
        "\n",
        "  timeDiffList.sort()\n",
        "  medianTimeDiff = statistics.median(timeDiffList)\n",
        "\n",
        "  timeDiffListCleaned = [getRightTimeDiff(timeDiffEl, medianTimeDiff) for timeDiffEl in timeDiffListOriginal]\n",
        "  return timeDiffListCleaned\n",
        "\n",
        "# add a relation type 0 (same_speaker), 1 (time_related) NOT COMPATIBLE WITH SplineNN\n",
        "def relation_type(cDf, edgesAsIndicesList):\n",
        "  relationTypesList = []\n",
        "  relationTypesListDebug = []\n",
        "  for edge in edgesAsIndicesList:\n",
        "    n1_index = edge[0]\n",
        "    n2_index = edge[1]\n",
        "\n",
        "    node1Speaker = cDf.loc[n1_index]['speaker']\n",
        "    node2Speaker = cDf.loc[n2_index]['speaker']\n",
        "    if node1Speaker == node2Speaker:\n",
        "      relationTypesList.append(0)\n",
        "      relationTypesListDebug.append([n1_index, n2_index, 0])\n",
        "    else:\n",
        "      relationTypesList.append(1)\n",
        "      relationTypesListDebug.append([n1_index, n2_index, 1])\n",
        "\n",
        "  relationTypesNpArr = np.array(relationTypesList)\n",
        "  return torch.nn.functional.one_hot(torch.tensor(relationTypesNpArr), num_classes=2).float()\n",
        "\n",
        "## END: EDGE ATTRIBUTE FUNCTIONS\n",
        "\n",
        "#------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "## START: EDGE NODE FEATURES FUNCTIONS\n",
        "\n",
        "# computes a node feature that has no information\n",
        "# used to compare a model having only with edge_attr and no node_features\n",
        "def empty(cDf):\n",
        "  emptyList = []\n",
        "  for index, utterance in cDf.iterrows():\n",
        "    emptyList.append(0)\n",
        "\n",
        "  return emptyList\n",
        "\n",
        "# computes the sentence embedding of each element in the dataframe\n",
        "def embeddings(cDf):\n",
        "  featureName = 'embeddings'\n",
        "  # if the embedding was already calculated\n",
        "  if not featureMustBeRecomputed(cDf, featureName):\n",
        "    embeddingList = cDf[featureName].tolist()\n",
        "  else:\n",
        "    embeddingList = []\n",
        "    cDf[featureName] = ''\n",
        "    for index, utterance in cDf.iterrows():\n",
        "      # 1. Extract node features from each utterance\n",
        "      try:\n",
        "        tokens = word_tokenize(utterance.text)\n",
        "      except Exception as e:\n",
        "        print('EXCEPTION: ')\n",
        "        print(e)\n",
        "        print(traceback.format_exc())\n",
        "        print('')\n",
        "        print('UTTERANCE')\n",
        "        print(utterance)\n",
        "        print(utterance.text)\n",
        "      # Convert tokens to sentence\n",
        "      sentence = ' '.join(tokens)\n",
        "      # Use Universal Sentence Encoder to obtain utterance embedding of size (512 => an array of 512 numbers)\n",
        "      utteranceEmbedding = list(universalSentenceEncoder([sentence])[0].numpy())\n",
        "      cDf.at[index, featureName] = utteranceEmbedding\n",
        "      embeddingList.append(utteranceEmbedding)\n",
        "\n",
        "  return embeddingList\n",
        "\n",
        "\n",
        "def sentiment(cDf):\n",
        "  sid = SentimentIntensityAnalyzer()\n",
        "  sentimentList = []\n",
        "\n",
        "  for index, utterance in cDf.iterrows():\n",
        "    sentiment_scores = sid.polarity_scores(utterance.text)\n",
        "    # Positive sentiment score\n",
        "    pos_score = sentiment_scores['pos']\n",
        "    # Negative sentiment score\n",
        "    neg_score = sentiment_scores['neg']\n",
        "    # Neutral sentiment score\n",
        "    neu_score = sentiment_scores['neu']\n",
        "    sentimentList.append([pos_score, neg_score, neu_score])\n",
        "\n",
        "  return sentimentList\n",
        "\n",
        "\n",
        "# gets the number of delta of a speaker\n",
        "def speaker_delta(cDf):\n",
        "  speakerDeltaList = []\n",
        "  for index, utterance in cDf.iterrows():\n",
        "    numOfDeltas = getSpeakersDeltaFromComment(index)\n",
        "    speakerDeltaList.append(numOfDeltas)\n",
        "\n",
        "  return speakerDeltaList\n",
        "\n",
        "\n",
        "# gets absolute position in a conversation\n",
        "def abs_position(cDf):\n",
        "  positionList = []\n",
        "  i = 0\n",
        "  for index, utterance in cDf.iterrows():\n",
        "    positionList.append(i)\n",
        "    i += 1\n",
        "\n",
        "  return positionList\n",
        "\n",
        "\n",
        "# gets the number of words of a comment\n",
        "def word_len(cDf):\n",
        "  wordLenList = []\n",
        "  i = 0\n",
        "  for index, utterance in cDf.iterrows():\n",
        "    numOfWords = getSentenceNumOfWords(utterance.text)\n",
        "    wordLenList.append(numOfWords)\n",
        "\n",
        "  return wordLenList\n",
        "\n",
        "\n",
        "# gets the number of words of a comment\n",
        "def emotions(cDf):\n",
        "  emotionsList = []\n",
        "  featureName = 'emotions'\n",
        "\n",
        "  if featureMustBeRecomputed(cDf, featureName):\n",
        "    cDf[featureName] = ''\n",
        "\n",
        "  for index, utterance in cDf.iterrows():\n",
        "    if utterance[featureName] == '':\n",
        "      try:\n",
        "        if len(utterance.text) > 1000:\n",
        "          midTextIndex = int(len(utterance.text) / 2)\n",
        "          t1 = np.array(getEmotionsScores(utterance.text[0:midTextIndex]))\n",
        "          t2 = np.array(getEmotionsScores(utterance.text[midTextIndex:-1]))\n",
        "          fourEmotions = list(t1 + t2 / 2)\n",
        "        else:\n",
        "          fourEmotions = getEmotionsScores(utterance.text)\n",
        "      except:\n",
        "        fourEmotions = [0,0,0,0]\n",
        "        print('Exception in emotions()')\n",
        "        print([fourEmotions, utterance.text])\n",
        "\n",
        "      cDf.at[index, featureName] = fourEmotions\n",
        "    else:\n",
        "      fourEmotions = utterance[featureName]\n",
        "    emotionsList.append(fourEmotions)\n",
        "\n",
        "  return emotionsList\n",
        "\n",
        "\n",
        "# gets the number of words of a comment\n",
        "def tf_idf(cDf, maxScores = 5):\n",
        "  tfIdfList = []\n",
        "  utteranceList = cDf['text'].map(preprocess_comment).map(lambda t: t.lower()).tolist()\n",
        "\n",
        "  vectorizer = TfidfVectorizer()\n",
        "  X = vectorizer.fit_transform(utteranceList)\n",
        "  vectorizer.get_feature_names_out()\n",
        "\n",
        "  tfIdfDf = pd.DataFrame(X[0].T.todense(), index=vectorizer.get_feature_names_out(), columns=[\"tf-idf\"])\n",
        "\n",
        "  avgTfIdfScore = float(tfIdfDf['tf-idf'].mean())\n",
        "\n",
        "  for index, utterance in cDf.iterrows():\n",
        "    utteranceScores = []\n",
        "    utteranceSentenceCleaned = preprocess_comment(utterance.text)\n",
        "    utteranceWords = utteranceSentenceCleaned.lower().split()\n",
        "    for word in utteranceWords:\n",
        "      try:\n",
        "        wordScoreSeries = tfIdfDf.loc[word]\n",
        "\n",
        "        if wordScoreSeries.shape[0] == 0:\n",
        "          wordScore = avgTfIdfScore\n",
        "        else:\n",
        "          wordScore = float(wordScoreSeries['tf-idf'])\n",
        "      except:\n",
        "         wordScore = avgTfIdfScore\n",
        "      # if the word does not exist in the td-idf dictionary add it as average score\n",
        "\n",
        "      utteranceScores.append(wordScore)\n",
        "\n",
        "    utteranceScores.sort()\n",
        "    utteranceScores.sort(reverse=True)\n",
        "    utterancesBestScores = utteranceScores[0:maxScores]\n",
        "\n",
        "    # if the sentence is shorter than 10 words append some empty scores\n",
        "    for i in range(10 - len(utterancesBestScores)):\n",
        "      utterancesBestScores.append(avgTfIdfScore)\n",
        "\n",
        "    # sort again after appending scores if an utterance had less than 10 words\n",
        "    utterancesBestScores.sort(reverse=True)\n",
        "\n",
        "    tfIdfList.append(utterancesBestScores)\n",
        "\n",
        "  return tfIdfList\n",
        "\n",
        "\n",
        "def interplay(cDf):\n",
        "  originalPostUtt = cDf.iloc[0]\n",
        "  wordsInOpAll = getWordsOfSentenceAsList(originalPostUtt.text)\n",
        "  stopwordsOfOp = getStopwordsInWordsList(wordsInOpAll)\n",
        "\n",
        "  opWithNoPunctuation = originalPostUtt.text.translate(str.maketrans('', '', string.punctuation))\n",
        "  wordsInOpWithNoPunctuation = getWordsOfSentenceAsList(opWithNoPunctuation)\n",
        "  contentWordsOfOp = getContentWordsInWordsList(wordsInOpWithNoPunctuation)\n",
        "\n",
        "  interplayList = []\n",
        "  i = 0\n",
        "  for index, utterance in cDf.iterrows():\n",
        "    wordsInArgumentAll = getWordsOfSentenceAsList(utterance.text)\n",
        "    argumentWithNoPunctuation = utterance.text.translate(str.maketrans('', '', string.punctuation))\n",
        "    wordsInArgumentWithNoPunctuation = getWordsOfSentenceAsList(argumentWithNoPunctuation)\n",
        "    contentWordsOfOp = getContentWordsInWordsList(wordsInOpWithNoPunctuation)\n",
        "\n",
        "    numOfcommonInAll = numberOfcommonWordsBetweenTwoListOfWords(wordsInOpAll, wordsInArgumentAll)\n",
        "    replyFracInAll = 0 if len(wordsInArgumentAll) == 0 else numOfcommonInAll / len(wordsInArgumentAll)\n",
        "\n",
        "    opFracInAll = 0 if len(wordsInOpAll) == 0 else numOfcommonInAll / len(wordsInOpAll)\n",
        "\n",
        "    contentWordsOfArgument = getContentWordsInWordsList(wordsInArgumentWithNoPunctuation)\n",
        "    numOfCommonWordsInContent = numberOfcommonWordsBetweenTwoListOfWords(contentWordsOfOp, contentWordsOfArgument)\n",
        "    replyFracInContent = 0 if len(contentWordsOfArgument) == 0 else numOfCommonWordsInContent / len(contentWordsOfArgument)\n",
        "\n",
        "    stopwordsOfArgument = getStopwordsInWordsList(wordsInArgumentAll)\n",
        "    numOfCommonStopwords = numberOfcommonWordsBetweenTwoListOfWords(stopwordsOfOp, stopwordsOfArgument)\n",
        "    replyFracInStopwords = 0 if len(stopwordsOfArgument) == 0 else numOfCommonStopwords / len(stopwordsOfArgument)\n",
        "\n",
        "    opFracInStopwords = 0 if len(stopwordsOfOp) == 0 else numOfCommonStopwords / len(stopwordsOfOp)\n",
        "\n",
        "    jaccardInContent = jaccard_similarity(contentWordsOfArgument, contentWordsOfOp)\n",
        "    jaccardInStopwords = jaccard_similarity(stopwordsOfArgument, stopwordsOfOp)\n",
        "\n",
        "    interplayList.append([\n",
        "        numOfcommonInAll,\n",
        "        replyFracInAll,\n",
        "        opFracInAll,\n",
        "        numOfCommonWordsInContent,\n",
        "        replyFracInContent,\n",
        "        numOfCommonStopwords,\n",
        "        replyFracInStopwords,\n",
        "        opFracInStopwords,\n",
        "        jaccardInContent,\n",
        "        jaccardInStopwords\n",
        "        ])\n",
        "\n",
        "  return interplayList\n",
        "\n",
        "dimensionalityMap = {\n",
        "    \"embeddings\": 512,\n",
        "    \"tf_idf\": 10,\n",
        "    \"interplay\": 10,\n",
        "    \"emotions\": 4,\n",
        "    \"sentiment\": 3,\n",
        "    \"empty\": 1,\n",
        "    \"abs_position\": 1,\n",
        "    \"word_len\": 1,\n",
        "    \"speaker_delta\": 1\n",
        "}\n",
        "\n",
        "\n",
        "## END: EDGE NODE FEATURES FUNCTIONS\n",
        "\n",
        "#------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "## START: CONF VARIABLES\n",
        "pss = 5\n",
        "pds = 0\n",
        "fss = 0\n",
        "fds = 0\n",
        "\n",
        "alwaysCompute = False\n",
        "\n",
        "#fetchMode = ['reply_to']\n",
        "#fetchMode = ['reply_to','timestamp']\n",
        "fetchMode = ['timestamp']\n",
        "#fetchMode = ['timestamp']\n",
        "\n",
        "#edgeAttributeFunctions = [relation_type]\n",
        "#edgeAttributeFunctions = [time_diff, relation_type]\n",
        "#edgeAttributeFunctions = [time_diff, text_sim, delta_ratio, word_len_ratio]\n",
        "#edgeAttributeFunctions = [time_diff]\n",
        "edgeAttributeFunctions = []\n",
        "\n",
        "#nodeFeaturesFunctions = [embeddings]\n",
        "#nodeFeaturesFunctions = [tf_idf]\n",
        "#nodeFeaturesFunctions = [emotions]\n",
        "#nodeFeaturesFunctions = [speaker_delta]\n",
        "#nodeFeaturesFunctions = [abs_position]\n",
        "#nodeFeaturesFunctions = [word_len]\n",
        "#nodeFeaturesFunctions = [embeddings, tf_idf, word_len]\n",
        "#nodeFeaturesFunctions = [embeddings, tf_idf, emotions]\n",
        "#nodeFeaturesFunctions = [embeddings, tf_idf, emotions, speaker_delta, abs_position, word_len]\n",
        "#nodeFeaturesFunctions = [tf_idf, emotions]\n",
        "#nodeFeaturesFunctions = [embeddings, tf_idf, sentiment]\n",
        "nodeFeaturesFunctions = [embeddings, tf_idf]\n",
        "#nodeFeaturesFunctions = [embeddings, word_len]\n",
        "#nodeFeaturesFunctions = [interplay]\n",
        "#nodeFeaturesFunctions = [embeddings, emotions]\n",
        "#nodeFeaturesFunctions = [embeddings, speaker_delta, abs_position, word_len]\n",
        "#nodeFeaturesFunctions = [abs_position, word_len]\n",
        "#nodeFeaturesFunctions = [empty]\n",
        "\n",
        "speakerLevelLabel = False\n",
        "\n",
        "## END: CONF VARIABLES\n",
        "\n",
        "#------------------------------------------------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "op = 'My name is mario compresoni and I am manager of Gasinplot'\n",
        "s2 = 'I do not Agree with you Mr compresoni, managers are not so good at Gasinplot'\n",
        "\n",
        "wordsInOpAll = getWordsOfSentenceAsList(op)\n",
        "opWithNoPunctuation = op.translate(str.maketrans('', '', string.punctuation))\n",
        "wordsInOpWithNoPunctuation = getWordsOfSentenceAsList(opWithNoPunctuation)\n",
        "contentWordsOfOp = getContentWordsInWordsList(wordsInOpWithNoPunctuation)\n",
        "stopwordsOfOp = getStopwordsInWordsList(wordsInOpAll)\n",
        "\n",
        "wordsInArgumentAll = getWordsOfSentenceAsList(s2)\n",
        "numOfcommonInAll = numberOfcommonWordsBetweenTwoListOfWords(wordsInOpAll, wordsInArgumentAll)\n",
        "replyFracInAll = numOfcommonInAll / len(wordsInArgumentAll)\n",
        "\n",
        "opFracInAll = numOfcommonInAll / len(wordsInOpAll)\n",
        "\n",
        "contentWordsOfArgument = getContentWordsInWordsList(wordsInArgumentAll)\n",
        "numOfCommonWordsInContent = numberOfcommonWordsBetweenTwoListOfWords(contentWordsOfOp, contentWordsOfArgument)\n",
        "replyFracInContent = numOfCommonWordsInContent / len(contentWordsOfArgument)\n",
        "\n",
        "stopwordsOfArgument = getStopwordsInWordsList(wordsInArgumentAll)\n",
        "numOfCommonStopwords = numberOfcommonWordsBetweenTwoListOfWords(stopwordsOfOp, stopwordsOfArgument)\n",
        "replyFracInStopwords = numOfCommonStopwords / len(stopwordsOfArgument)\n",
        "\n",
        "opFracInStopwords = numOfCommonStopwords / len(stopwordsOfOp)\n",
        "\n",
        "jaccardInContent = jaccard_similarity(contentWordsOfArgument, contentWordsOfOp)\n",
        "jaccardInStopwords = jaccard_similarity(stopwordsOfArgument, stopwordsOfOp)\n",
        "\n",
        "print([\n",
        "    numOfcommonInAll,\n",
        "    replyFracInAll,\n",
        "    opFracInAll,\n",
        "    numOfCommonWordsInContent,\n",
        "    replyFracInContent,\n",
        "    numOfCommonStopwords,\n",
        "    replyFracInStopwords,\n",
        "    opFracInStopwords,\n",
        "    jaccardInContent,\n",
        "    jaccardInStopwords\n",
        "    ])\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "DEhMZHlk4cHX",
        "outputId": "87e3ec46-d1dd-4390-a612-8093ffcde20a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nop = 'My name is mario compresoni and I am manager of Gasinplot'\\ns2 = 'I do not Agree with you Mr compresoni, managers are not so good at Gasinplot'\\n\\nwordsInOpAll = getWordsOfSentenceAsList(op)\\nopWithNoPunctuation = op.translate(str.maketrans('', '', string.punctuation))\\nwordsInOpWithNoPunctuation = getWordsOfSentenceAsList(opWithNoPunctuation)\\ncontentWordsOfOp = getContentWordsInWordsList(wordsInOpWithNoPunctuation)\\nstopwordsOfOp = getStopwordsInWordsList(wordsInOpAll)\\n\\nwordsInArgumentAll = getWordsOfSentenceAsList(s2)\\nnumOfcommonInAll = numberOfcommonWordsBetweenTwoListOfWords(wordsInOpAll, wordsInArgumentAll)\\nreplyFracInAll = numOfcommonInAll / len(wordsInArgumentAll)\\n\\nopFracInAll = numOfcommonInAll / len(wordsInOpAll)\\n\\ncontentWordsOfArgument = getContentWordsInWordsList(wordsInArgumentAll)\\nnumOfCommonWordsInContent = numberOfcommonWordsBetweenTwoListOfWords(contentWordsOfOp, contentWordsOfArgument)\\nreplyFracInContent = numOfCommonWordsInContent / len(contentWordsOfArgument)\\n\\nstopwordsOfArgument = getStopwordsInWordsList(wordsInArgumentAll)\\nnumOfCommonStopwords = numberOfcommonWordsBetweenTwoListOfWords(stopwordsOfOp, stopwordsOfArgument)\\nreplyFracInStopwords = numOfCommonStopwords / len(stopwordsOfArgument)\\n\\nopFracInStopwords = numOfCommonStopwords / len(stopwordsOfOp)\\n\\njaccardInContent = jaccard_similarity(contentWordsOfArgument, contentWordsOfOp)\\njaccardInStopwords = jaccard_similarity(stopwordsOfArgument, stopwordsOfOp)\\n\\nprint([\\n    numOfcommonInAll,\\n    replyFracInAll,\\n    opFracInAll,\\n    numOfCommonWordsInContent,\\n    replyFracInContent,\\n    numOfCommonStopwords,\\n    replyFracInStopwords,\\n    opFracInStopwords,\\n    jaccardInContent,\\n    jaccardInStopwords\\n    ])\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "QnsMEbSyiAHe"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "$e = are the edge attributes names\n",
        "$l = is the way the links are constructed in the graph\n",
        "$n = are the node features names\n",
        "'''\n",
        "if len(edgeAttributeFunctions) > 0:\n",
        "  edgeAttributesStringJoined = '&'.join([f.__name__ for f in edgeAttributeFunctions])\n",
        "  edgeAttributesString = '$e=' + edgeAttributesStringJoined\n",
        "else:\n",
        "  edgeAttributesString = ''\n",
        "\n",
        "fetchModeStringJoined = '&'.join(fetchMode)\n",
        "fetchModeString = '$l=' + fetchModeStringJoined\n",
        "\n",
        "nodeFeaturesStringJoined = '-'.join([f.__name__ for f in nodeFeaturesFunctions])\n",
        "nodeFeaturesString = '$n=' + nodeFeaturesStringJoined"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "RhjDaMnBq2MP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "962d235d-1d23-4ddf-9381-7274daf8a4f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 17] File exists: '/content/drive/My Drive/datasets/winning-args-corpus/$pss5$pds0$fss0$fds0$n=embeddings-tf_idf$l=timestamp'\n"
          ]
        }
      ],
      "source": [
        "baseDir = '/content/drive/My Drive/datasets/winning-args-corpus/'\n",
        "postfix = nodeFeaturesString + fetchModeString + '' + edgeAttributesString\n",
        "dirName = '$pss' + str(pss) + '$pds' + str(pds) + '$fss' + str(fss) + '$fds' + str(fds)  + postfix\n",
        "fullDirectory = baseDir + dirName\n",
        "try:\n",
        "  os.mkdir(fullDirectory)\n",
        "except Exception as e:\n",
        "  print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "j604nKCQkIYb"
      },
      "outputs": [],
      "source": [
        "def preprocess_comment(comment, stop_words = stop_words):\n",
        "    # Replace links with \"URL\"\n",
        "    try:\n",
        "      comment = re.sub(r'http\\S+|www\\S+', 'URL', comment)\n",
        "      # Replace emoticons\n",
        "      comment = emoji.demojize(comment)\n",
        "      # Replace special chars\n",
        "      comment = re.sub(\"[^\\w\\s]\", \"\", comment)\n",
        "    except Exception as e:\n",
        "      print('EXC: ---')\n",
        "      print(e)\n",
        "      print(str(comment))\n",
        "      print(traceback.format_exc())\n",
        "      print('')\n",
        "\n",
        "    # Tokenize comment text and convert tokens to lowercase\n",
        "    tokens = [token.lower() for token in word_tokenize(comment)]\n",
        "    # Remove stopwords\n",
        "    # tokens = [token for token in tokens if token not in stop_words]\n",
        "    # Join tokens back into a comment text\n",
        "    preprocessed_comment = ' '.join(tokens)\n",
        "    return preprocessed_comment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "satiwnEXv8hX"
      },
      "outputs": [],
      "source": [
        "# Define the GCN model\n",
        "'''\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr = None):\n",
        "        if edge_attr != None:\n",
        "          x = self.conv1(x, edge_index, edge_attr)\n",
        "          x = F.leaky_relu(x)\n",
        "          x = self.conv2(x, edge_index, edge_attr)\n",
        "        else:\n",
        "          x = self.conv1(x, edge_index)\n",
        "          x = F.leaky_relu(x)\n",
        "          x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "\n",
        "class GAT(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, heads = 4):\n",
        "        super(GAT, self).__init__()\n",
        "        self.conv1 = GATConv(in_channels, hidden_channels, heads=heads)\n",
        "        self.conv2 = GATConv(hidden_channels * heads, out_channels, heads=1)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr = None):\n",
        "        if edge_attr != None:\n",
        "          x = self.conv1(x, edge_index, edge_attr)\n",
        "          x = F.leaky_relu(x)\n",
        "          x = self.conv2(x, edge_index, edge_attr)\n",
        "        else:\n",
        "          x = self.conv1(x, edge_index)\n",
        "          x = F.leaky_relu(x)\n",
        "          x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "'''\n",
        "\n",
        "class SplineNN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, dim = 1):\n",
        "        super().__init__()\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        self.convs.append(SplineConv(in_channels, hidden_channels, dim=dim, kernel_size=2))\n",
        "        self.convs.append(SplineConv(hidden_channels, out_channels, dim=dim, kernel_size=2))\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr = None, dropout = True):\n",
        "        conv1 = self.convs[0]\n",
        "        conv2 = self.convs[1]\n",
        "        x = F.dropout(x, training=self.training)\n",
        "\n",
        "        x = F.elu(conv1(x, edge_index, edge_attr))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = conv2(x, edge_index, edge_attr)\n",
        "        #return F.log_softmax(x, dim=1)\n",
        "        return x\n",
        "\n",
        "class DeeperGCN(torch.nn.Module):\n",
        "    def __init__(self, data, in_channels, hidden_channels, out_channels, num_layers):\n",
        "        super().__init__()\n",
        "\n",
        "        self.node_encoder = Linear(in_channels, hidden_channels)\n",
        "        self.edge_encoder = Linear(data.edge_attr.size(-1), hidden_channels)\n",
        "\n",
        "        self.layers = torch.nn.ModuleList()\n",
        "        for i in range(1, num_layers + 1):\n",
        "            conv = GENConv(hidden_channels, hidden_channels, aggr='softmax',\n",
        "                           t=1.0, learn_t=True, num_layers=2, norm='layer')\n",
        "            norm = nn.LayerNorm(hidden_channels, elementwise_affine=True)\n",
        "            act = ReLU(inplace=True)\n",
        "\n",
        "            layer = DeepGCNLayer(conv, norm, act, block='res+', dropout=0.1,\n",
        "                                 ckpt_grad=i % 3)\n",
        "            self.layers.append(layer)\n",
        "\n",
        "        self.lin = Linear(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr):\n",
        "        x = self.node_encoder(x)\n",
        "        edge_attr = self.edge_encoder(edge_attr)\n",
        "\n",
        "        x = self.layers[0].conv(x, edge_index, edge_attr)\n",
        "\n",
        "        for layer in self.layers[1:]:\n",
        "            x = layer(x, edge_index, edge_attr)\n",
        "\n",
        "        x = self.layers[0].act(self.layers[0].norm(x))\n",
        "        x = F.dropout(x, p=0.1, training=self.training)\n",
        "\n",
        "        return self.lin(x)\n",
        "\n",
        "\n",
        "class GSAGEv2(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers, aggr = 'mean'):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        self.convs.append(SAGEConv(in_channels, hidden_channels, aggr))\n",
        "        for _ in range(num_layers - 1):\n",
        "            self.convs.append(SAGEConv(hidden_channels, hidden_channels, aggr))\n",
        "        self.lin = nn.Linear(hidden_channels, out_channels)\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr = None):\n",
        "        for i, conv in enumerate(self.convs):\n",
        "            x = conv(x, edge_index)\n",
        "            if i != self.num_layers - 1:\n",
        "                x = F.leaky_relu(x)\n",
        "                x = F.dropout(x, p=0.5, training=self.training)\n",
        "        return self.lin(x)\n",
        "\n",
        "\n",
        "class GSAGE(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(GSAGE, self).__init__()\n",
        "        self.conv1 = SAGEConv(in_channels, hidden_channels, 'mean')\n",
        "        self.conv2 = SAGEConv(hidden_channels, out_channels, 'mean')\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr = None):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.leaky_relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "class Baseline(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(Baseline, self).__init__()\n",
        "        self.fc1 = nn.Linear(in_channels, hidden_channels)\n",
        "        self.fc2 = nn.Linear(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index = None, edge_attr = None):\n",
        "        x = self.fc1(x)\n",
        "        x = F.leaky_relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "zUiQB61QGDC6"
      },
      "outputs": [],
      "source": [
        "class GraphVisualization:\n",
        "    def __init__(self):\n",
        "\n",
        "        # visual is a list which stores all\n",
        "        # the set of edges that constitutes a\n",
        "        # graph\n",
        "        self.visual = []\n",
        "\n",
        "    # addEdge function inputs the vertices of an\n",
        "    # edge and appends it to the visual list\n",
        "    def addEdge(self, a, b):\n",
        "        temp = [a, b]\n",
        "        self.visual.append(temp)\n",
        "\n",
        "    # In visualize function G is an object of\n",
        "    # class Graph given by networkx G.add_edges_from(visual)\n",
        "    # creates a graph with a given list\n",
        "    # nx.draw_networkx(G) - plots the graph\n",
        "    # plt.show() - displays the graph\n",
        "    def visualize(self):\n",
        "        G = nx.Graph()\n",
        "        G.add_edges_from(self.visual)\n",
        "        nx.draw_networkx(G)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "qVwH36R8wxcL"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "# PREPROCESSING\n",
        "- delete all rows where (speaker == \"[deleted]\" or speaker === \"DeltaBot\" or text == \"[deleted]\")\n",
        "- remove \"stopwords\", replace links with \"URL\", replace emojis\n",
        "- add a column to C called \"embeddings\"\n",
        "- assign the 0 (NO DELTA) label to all utterances\n",
        "- get all utterances containing ∆:\n",
        "  - assign the 1 (DELTA) label to the \"reply_to\" ID. (Do not create an embedding of the ∆ utterance)\n",
        "- remove the utterance containing \"∆\" or \"#8710;\" or \"!delta\" from the C\n",
        "- the first utterance (the root one) has timestamp = None, replace it with timestamp=0\n",
        "- sort C by timestamp => sort_values(by=['timestamp'])\n",
        "'''\n",
        "def preprocessConversationDf(cDf):\n",
        "  # delete all rows where (speaker == \"[deleted]\" or speaker === \"DeltaBot\" or text == \"[deleted]\")\n",
        "  cDf = cDf.loc[(cDf['speaker'] != '[deleted]') & (cDf['speaker'] != 'DeltaBot') & (cDf['text'] != '[deleted]')]\n",
        "\n",
        "  cDf['utterance_label'] = np.zeros(cDf.shape[0]) # 0 is NO DELTA\n",
        "\n",
        "  cdfDelta = cDf.loc[(cDf['text'].str.contains('∆')) | (cDf['text'].str.contains('#8710;')) | (cDf['text'].str.contains('!delta'))]\n",
        "  deltaIndeces = []\n",
        "  for index, row in cdfDelta.iterrows():\n",
        "    replyTo = row['reply_to']\n",
        "    cDf.at[replyTo, 'utterance_label'] = 1 # 1 is DELTA\n",
        "    deltaIndeces.append(index)\n",
        "\n",
        "  cDf.drop(index=deltaIndeces, inplace = True)\n",
        "  cDf['text'] = cDf['text'].map(preprocess_comment)\n",
        "  cDfTimestampNoneIndex = cDf.loc[cDf['timestamp'].isna()]\n",
        "\n",
        "  if cDfTimestampNoneIndex.shape[0] > 0:\n",
        "    cDf.at[cDfTimestampNoneIndex.iloc[0].name, 'timestamp'] = 0\n",
        "  # remove all rows with nan cells\n",
        "  cDf = cDf.dropna(subset=['speaker', 'text'])\n",
        "\n",
        "  return cDf.sort_values(by=['timestamp'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "TlYHkt8B5ZoB",
        "outputId": "41e9dd6f-3d03-44d6-d947-33ddcbbe7b97"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# CONVERSATION GRAPH CREATION\\n- for each utterance\\n   - create it\\'s embedding representation and add it to the dataframe column \"embeddings\"\\n   - link it to past utterances (with a max, e.g. max 5) of the same \"speaker\"\\n   - link it to past past utterances (with a max, e.g. max 10) by timestamp, excluding same-speaker utterances\\n   - link the first post\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "'''\n",
        "# CONVERSATION GRAPH CREATION\n",
        "- for each utterance\n",
        "   - create it's embedding representation and add it to the dataframe column \"embeddings\"\n",
        "   - link it to past utterances (with a max, e.g. max 5) of the same \"speaker\"\n",
        "   - link it to past past utterances (with a max, e.g. max 10) by timestamp, excluding same-speaker utterances\n",
        "   - link the first post\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "g9QMEo1Pw2zZ"
      },
      "outputs": [],
      "source": [
        "## START CREATE RELATIONSHIPS (LINKS) FUNCTIONS\n",
        "# relationships are the linked edges of a node (represented by index)\n",
        "# index is the index of the node which we want to get the relationships from\n",
        "\n",
        "# gets the relationships based on the number of \"past and future numbers\" by timestamp\n",
        "# (i.e. does not consider subtrees in the conversation)\n",
        "def getRelationshipsByTimestamp(index, cDf, pastSpeakerMax = 3, pastUtterancesMax = 5, futureSameSpeakerMax = 3, futureUtterancesMax = 5):\n",
        "  relationships = set()\n",
        "  utterance = cDf.loc[index]\n",
        "\n",
        "  # comments coming from the same speaker\n",
        "  sameSpeakerCdf = cDf.loc[cDf['speaker'] == utterance.speaker]\n",
        "\n",
        "  # PAST UTTERANCES LINK\n",
        "  # get the previous utterances by timestamp of the same speaker. Past with respect to \"index\" param\n",
        "  # get the location of \"index element\" relative to the new same speaker dataframe\n",
        "  sameSpeakerLoc = sameSpeakerCdf.index.get_loc(index)\n",
        "\n",
        "  sameSpeakerCdfPastUtterances = sameSpeakerCdf.iloc[max(0, sameSpeakerLoc - pastSpeakerMax):sameSpeakerLoc]\n",
        "  relationships.update(sameSpeakerCdfPastUtterances.index)\n",
        "\n",
        "  # get the location of \"index element\" relative to the cDf dataframe\n",
        "  loc = cDf.index.get_loc(index)\n",
        "  pastUtterancesByTimestamp = cDf.iloc[max(0, loc - pastUtterancesMax):loc]\n",
        "  relationships.update(pastUtterancesByTimestamp.index)\n",
        "\n",
        "  # FUTURE UTTERANCES LINK\n",
        "  # get the next utterances by timestamp of the same speaker. Future with respect to \"index\" param\n",
        "  # get the location of \"index element\" relative to the new same speaker dataframe\n",
        "  indexOfFutureLimit = min(sameSpeakerLoc + futureSameSpeakerMax, sameSpeakerCdf.shape[0])\n",
        "  sameSpeakerCdfFutureUtterances = sameSpeakerCdf.iloc[sameSpeakerLoc: indexOfFutureLimit]\n",
        "  relationships.update(sameSpeakerCdfFutureUtterances.index)\n",
        "\n",
        "  # get the past previous utterances by timestamp. Past with respect to \"index\" param\n",
        "  # get the location of \"index element\" relative to the cDf dataframe\n",
        "  loc = cDf.index.get_loc(index)\n",
        "  indexOfFutureLimit = min(loc + futureUtterancesMax, cDf.shape[0])\n",
        "  futureUtterancesByTimestamp = cDf.iloc[loc: indexOfFutureLimit]\n",
        "  relationships.update(futureUtterancesByTimestamp.index)\n",
        "\n",
        "  # add a link also to the first post (the one starting the conversation)\n",
        "  # AND add self connection (check GNNs theory to understand why is useful)\n",
        "  relationships.update({cDf.iloc[0].name, index})\n",
        "\n",
        "  return relationships\n",
        "\n",
        "\n",
        "# returns relationships based on whether a text is a \"reply to\" another one\n",
        "def getRelationshipsByReplyTo(index, cDf, pastSameSpeakerMax = 3, pastUtterancesMax = 5, futureSameSpeakerMax = 3, futureUtterancesMax = 5):\n",
        "  relationships = set()\n",
        "  utterance = cDf.loc[index]\n",
        "  pastSameSpeakerCount = 0\n",
        "  pastUtteranceCount = 0\n",
        "  futureSameSpeakerCount = 0\n",
        "  futureUtteranceCount = 0\n",
        "\n",
        "  dfLength = cDf.shape[0]\n",
        "\n",
        "  # GET PAST UTTERANCES BY REPLY TO\n",
        "  currentUtterance = utterance\n",
        "  lastUtteranceIndex = cDf.iloc[cDf.shape[0] - 1].name\n",
        "  while pastSameSpeakerCount < pastSameSpeakerMax or pastUtteranceCount < pastUtterancesMax:\n",
        "    utteranceReplyToIndex = currentUtterance.reply_to\n",
        "\n",
        "    if utteranceReplyToIndex == None:\n",
        "      break\n",
        "\n",
        "    try:\n",
        "      utteranceReplyTo = cDf.loc[utteranceReplyToIndex]\n",
        "    except:\n",
        "      # happening when a comment has been deleted\n",
        "      break\n",
        "\n",
        "    # if the number of past utterances is achieved but the speaker is not the same we have no interest in adding\n",
        "    # the utterance index to the relationships of the considered utterances\n",
        "    if pastUtteranceCount >= pastUtterancesMax and utteranceReplyTo.speaker != currentUtterance.speaker:\n",
        "      currentUtterance = utteranceReplyTo\n",
        "      continue\n",
        "\n",
        "    relationships.add(utteranceReplyToIndex)\n",
        "\n",
        "    if utteranceReplyTo.speaker == currentUtterance.speaker:\n",
        "      pastSameSpeakerCount += 1\n",
        "\n",
        "    if pastSameSpeakerCount != pastSameSpeakerMax:\n",
        "      pastUtteranceCount += 1\n",
        "\n",
        "    currentUtterance = utteranceReplyTo\n",
        "\n",
        "  # get the location of \"index element\" relative to the cDf dataframe\n",
        "  currentUtteranceLoc = cDf.index.get_loc(index)\n",
        "  # GET FUTURE UTTERANCES BY REPLY TO\n",
        "  currentUtterance = utterance\n",
        "  while futureSameSpeakerCount < futureSameSpeakerMax and futureUtteranceCount < futureUtterancesMax:\n",
        "    if currentUtteranceLoc + 1 >= dfLength:\n",
        "      break\n",
        "\n",
        "    nextUtterance = cDf.iloc[currentUtteranceLoc + 1]\n",
        "\n",
        "    if nextUtterance.reply_to == currentUtterance.name:\n",
        "      relationships.add(nextUtterance.name)\n",
        "\n",
        "      if nextUtterance.speaker == currentUtterance.speaker:\n",
        "        futureSameSpeakerCount += 1\n",
        "      else:\n",
        "        futureUtteranceCount += 1\n",
        "\n",
        "    currentUtterance = nextUtterance\n",
        "    currentUtteranceLoc += 1\n",
        "\n",
        "  return relationships\n",
        "\n",
        "\n",
        "# returns relationships based on the similarity between text\n",
        "def getRelationshipsBySimilarity(index, cDf, similarityThreshold = 0.5, similarityFunction = jaccard_similarity):\n",
        "  relationships = set()\n",
        "  utterance = cDf.loc[index]\n",
        "  utteranceText = utterance.text\n",
        "\n",
        "  # this function is defined inside getRelationshipsBySimilarity cause it needs to access utteranceText\n",
        "  def similarityIsInThreshold(row):\n",
        "    tr = similarityThreshold\n",
        "    return similarityFunction(row.text, utteranceText) > tr and similarityFunction(row.text, utteranceText) != 1\n",
        "\n",
        "  mask = cDf.apply(similarityIsInThreshold, axis=1)\n",
        "  dfAboveSimilarityThreshold = cDf[mask]\n",
        "\n",
        "  relationships.update(dfAboveSimilarityThreshold.index)\n",
        "\n",
        "  return relationships\n",
        "\n",
        "## END CREATE RELATIONSHIPS (LINKS) FUNCTIONS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "DvmGFaHdF5Wk"
      },
      "outputs": [],
      "source": [
        "# it calulates tensors to be passed to the model\n",
        "# this is useful to calculate node features tensors and edge attributes tensors\n",
        "def calculateTensorList(cDf, attributeFunctions, edgesAsIndicesList = None):\n",
        "  attributes = []\n",
        "  if len(attributeFunctions) > 0:\n",
        "    for attrFunction in attributeFunctions:\n",
        "      # a function might return a tensor or a list\n",
        "      if edgesAsIndicesList == None:\n",
        "        attrMaybeTensor = attrFunction(cDf)\n",
        "      else:\n",
        "        attrMaybeTensor = attrFunction(cDf, edgesAsIndicesList)\n",
        "\n",
        "      # transform the attribute in a tensor only if needed\n",
        "      if not torch.is_tensor(attrMaybeTensor):\n",
        "        attr_el = np.array(attrMaybeTensor)\n",
        "\n",
        "        if type(attrMaybeTensor[0]) is not list:\n",
        "          attr_el_tensor = torch.tensor(attr_el, dtype=torch.float).unsqueeze(1)\n",
        "        else:\n",
        "          attr_el_tensor = torch.tensor(attr_el, dtype=torch.float)\n",
        "      else:\n",
        "        attr_el_tensor = attrMaybeTensor\n",
        "\n",
        "      #print('edge_attr_el_tensor shape of func ' + edgeAttrFunction.__name__)\n",
        "      #print([edge_attr_el_tensor.shape, edge_attr_el_tensor.min(), edge_attr_el_tensor.max()])\n",
        "      attributes.append(attr_el_tensor)\n",
        "\n",
        "  return attributes\n",
        "\n",
        "def getEdgeAttributes(cDf, edgesAsIndicesList):\n",
        "  return calculateTensorList(cDf, edgeAttributeFunctions, edgesAsIndicesList)\n",
        "\n",
        "def getNodeFeatures(cDf):\n",
        "  return calculateTensorList(cDf, nodeFeaturesFunctions)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lWQ6rkX1muKh"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Ymke_4wK5kM-"
      },
      "outputs": [],
      "source": [
        "def plotConversation(edges):\n",
        "  G = GraphVisualization()\n",
        "  for i, edge in edges:\n",
        "    G.addEdge(i, edge)\n",
        "\n",
        "  G.visualize()\n",
        "\n",
        "def getSpeakerNameInConversation(speaker, conversationId):\n",
        "  return speaker + \"-\" + conversationId\n",
        "\n",
        "def createConversationGraph(cDf, conversationId, showPlot):\n",
        "  node_labels = []\n",
        "  utterances_speakers = []\n",
        "  edges = set()\n",
        "  edgesAsIndices = set()\n",
        "\n",
        "  if pss != 0 or pds != 0 or fss != 0 or fds != 0 or 'similarity' in fetchMode:\n",
        "    # Create a dictionary to map utterance IDs to node indices\n",
        "    node_index_map = {}\n",
        "\n",
        "    j = 0\n",
        "    for idx, utt in cDf.iterrows():\n",
        "      node_index_map[idx] = j\n",
        "      j += 1\n",
        "\n",
        "  try:\n",
        "    i = 0\n",
        "    for index, utterance in cDf.iterrows():\n",
        "      #node_features.append(utterance.embeddings)\n",
        "\n",
        "      # 2. Define the edge indices based on the graph structure and the node labels\n",
        "      node_labels.append(utterance.utterance_label)\n",
        "      speakerInConversation = getSpeakerNameInConversation(utterance.speaker, conversationId)\n",
        "      utterances_speakers.append(speakerInConversation)\n",
        "\n",
        "      relationshipsSet = set()\n",
        "\n",
        "      # do not add any links for the baseline model\n",
        "      if pss != 0 or pds != 0 or fss != 0 or fds != 0 or 'similarity' in fetchMode:\n",
        "        # Determine the relationships (edges) for each utterance\n",
        "        if 'timestamp' in fetchMode:\n",
        "          relationshipsByTimestamp = getRelationshipsByTimestamp(index, cDf, pss, pds, fss, fds)\n",
        "          relationshipsSet.update(relationshipsByTimestamp)\n",
        "\n",
        "        if 'reply_to' in fetchMode:\n",
        "          relationshipsByReplyTo = getRelationshipsByReplyTo(index, cDf, pss, pds, fss, fds)\n",
        "          relationshipsSet.update(relationshipsByReplyTo)\n",
        "\n",
        "        if 'similarity' in fetchMode:\n",
        "          relationshipsBySimilarity = getRelationshipsBySimilarity(index, cDf)\n",
        "          relationshipsSet.update(relationshipsBySimilarity)\n",
        "\n",
        "        relationships = list(relationshipsSet)\n",
        "\n",
        "        # Add the edges to the list\n",
        "        for related_utterance_index in relationships:\n",
        "            if related_utterance_index in node_index_map:\n",
        "                related_utterance_i = node_index_map[related_utterance_index]\n",
        "                edges.add((i, related_utterance_i))\n",
        "                edgesAsIndices.add((index, related_utterance_index))\n",
        "\n",
        "      i += 1\n",
        "\n",
        "    edgesList = list(edges)\n",
        "    edgesAsIndicesList = list(edgesAsIndices)\n",
        "\n",
        "    node_features = getNodeFeatures(cDf)\n",
        "    edge_attributes = getEdgeAttributes(cDf, edgesAsIndicesList)\n",
        "\n",
        "    if showPlot:\n",
        "      print('')\n",
        "      plotConversation(edgesList)\n",
        "      print(edgesList)\n",
        "\n",
        "    # 4. Create a Data object for the conversation\n",
        "    x = torch.cat(node_features, dim=1)\n",
        "    edge_index = torch.tensor(edgesList, dtype=torch.long).t().contiguous()\n",
        "    y = torch.tensor(node_labels, dtype=torch.long)\n",
        "\n",
        "    if len(edgeAttributeFunctions) > 0:\n",
        "      # concatenating on the 2nd dimenstion all edge attributes\n",
        "      edge_attr = torch.cat(edge_attributes, dim=1)\n",
        "      data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y, utterances_speakers=utterances_speakers)\n",
        "    else:\n",
        "      data = Data(x=x, edge_index=edge_index, y=y, utterances_speakers=utterances_speakers)\n",
        "    return data\n",
        "  except Exception as e:\n",
        "    print('EXC: ---')\n",
        "    print(e)\n",
        "    print(traceback.format_exc())\n",
        "    print('')\n",
        "    return False\n",
        "\n",
        "def addLabelOneToAllUtterancesOfSpeakersAwarded(cDf):\n",
        "  speakersAwardedInConversation = set()\n",
        "  for index, utterance in cDf.iterrows():\n",
        "    if utterance['utterance_label'] == 1:\n",
        "      speakersAwardedInConversation.add(utterance.speaker)\n",
        "\n",
        "  for index, utt in cDf.iterrows():\n",
        "    # if the speaker is an awarded one and the label is set to 0 and the message is longer than 200 characters\n",
        "    # then label the comment as persuasive; the idea behind the 200 characters check is that only longer comments\n",
        "    # are able to be persuasive\n",
        "    if utt.speaker in speakersAwardedInConversation and utt['utterance_label'] == 0 and len(utt.text) > 200:\n",
        "      cDf.at[index, 'utterance_label'] = 0.5\n",
        "\n",
        "  return cDf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOaC1urevoSs",
        "outputId": "50e309bc-38ac-47f1-b23e-ff9bdf46c4b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "300\n",
            "\n",
            "600\n",
            "\n",
            "900\n",
            "\n",
            "1200\n",
            "\n",
            "1500\n",
            "\n",
            "2100\n",
            "\n",
            "2400\n",
            "\n",
            "2700\n",
            "\n",
            "3000\n"
          ]
        }
      ],
      "source": [
        "i = 0\n",
        "maxConversations = 3051\n",
        "#maxConversations = 300\n",
        "#maxConversations = 10\n",
        "\n",
        "persuasiveSpeakerCommentsLabeledAs1 = False\n",
        "\n",
        "#allConversationIds = corpus.get_conversation_ids()\n",
        "#conversationIds = allConversationIds[i:maxConversations]\n",
        "\n",
        "# show the plot only if there is a single conversation processed\n",
        "if maxConversations < 5:\n",
        "  showPlot = True\n",
        "else:\n",
        "  showPlot = False\n",
        "\n",
        "data_list = []\n",
        "convIds = set()\n",
        "numberOfDuplicatesConvs = 0\n",
        "\n",
        "preprocessedDatasetDir = baseDir + 'preprocessed-df/'\n",
        "\n",
        "# Process each conversation\n",
        "for filenameWithExtension in os.listdir(preprocessedDatasetDir):\n",
        "#for conversationId in conversationIds:\n",
        "    if filenameWithExtension == '.ipynb_checkpoints':\n",
        "      continue\n",
        "\n",
        "    # the file name is equal to the conversationId\n",
        "    conversationId = filenameWithExtension.replace('.json', '')\n",
        "\n",
        "    # if the conversation is stored as a duplicate, continue\n",
        "    if '(1)' in conversationId:\n",
        "      continue\n",
        "\n",
        "    if conversationId in convIds:\n",
        "      numberOfDuplicatesConvs += 1\n",
        "      print('Duplicate conversation ' + str(conversationId))\n",
        "      continue\n",
        "\n",
        "    if i == maxConversations:\n",
        "      break\n",
        "\n",
        "    convIds.add(conversationId)\n",
        "\n",
        "    conversationFileName = fullDirectory + '/instance_' + str(i) + '.pt'\n",
        "\n",
        "    try:\n",
        "      if not speakerLevelLabel:\n",
        "        # load the preprocessed result for a specific graph structure\n",
        "        conversationDataGraph = torch.load(conversationFileName)\n",
        "      else:\n",
        "        raise Exception('need to read the file from json as the label must be set at speaker level')\n",
        "    except:\n",
        "      try:\n",
        "        # load the preprocessed df of all comments (this does not include their graph structure)\n",
        "        conversationDfPreprocessed = pd.read_json(preprocessedDatasetDir + conversationId + '.json')\n",
        "      except:\n",
        "        # given a conversation dataframe C having the following columns ['timestamp', 'speaker','reply_to', 'text']\n",
        "        # (for now do not add 'meta.author_flair_text' which is the number of deltas awarded in the past)\n",
        "\n",
        "        conversation = corpus.get_conversation(conversationId)\n",
        "        conversationDf = conversation.get_utterances_dataframe()[['timestamp', 'speaker','reply_to', 'text']]\n",
        "        try:\n",
        "          conversationDfPreprocessed = preprocessConversationDf(conversationDf)\n",
        "          conversationDfPreprocessed.to_json(baseDir + 'preprocessed-df/' + conversationId + '.json')\n",
        "        except Exception as e:\n",
        "          print('EXC conversationDfPreprocessed: ---')\n",
        "          print(e)\n",
        "          print(traceback.format_exc())\n",
        "          print('')\n",
        "\n",
        "      if speakerLevelLabel and persuasiveSpeakerCommentsLabeledAs1:\n",
        "          conversationDfPreprocessed = addLabelOneToAllUtterancesOfSpeakersAwarded(conversationDfPreprocessed)\n",
        "\n",
        "      conversationDataGraph = createConversationGraph(conversationDfPreprocessed, conversationId, showPlot)\n",
        "\n",
        "      # we want to save the file only for labels put at the comment level, to avoid confusion in the files\n",
        "      #if not speakerLevelLabel:\n",
        "          #conversationDfPreprocessed.to_json(baseDir + 'preprocessed-df/' + conversationId + '.json')\n",
        "\n",
        "      if conversationDataGraph and not speakerLevelLabel:\n",
        "        torch.save(conversationDataGraph, conversationFileName)\n",
        "\n",
        "    if conversationDataGraph:\n",
        "      data_list.append(conversationDataGraph)\n",
        "\n",
        "    if i % 300 == 0 and i != 0:\n",
        "      print('')\n",
        "      print(i)\n",
        "\n",
        "    i += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "osk438HPLPaT"
      },
      "outputs": [],
      "source": [
        "# conversationDfPreprocessed[['speaker','utterance_label']] (print this for debugging speaker level labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrFWBzz4wUsK",
        "outputId": "26241bc1-320f-405a-dc01-9460a03bffe5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3051"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "len(data_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "VN1gyI-bMbPQ"
      },
      "outputs": [],
      "source": [
        "speakersMapCount = {}\n",
        "\n",
        "dataListIndex = 0\n",
        "for data_el in data_list:\n",
        "  for speaker in data_el.utterances_speakers:\n",
        "      if speaker not in speakersMapCount:\n",
        "        speakersMapCount[speaker] = [dataListIndex]\n",
        "      elif dataListIndex not in speakersMapCount[speaker]:\n",
        "        speakersMapCount[speaker].append(dataListIndex)\n",
        "  dataListIndex += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "71a8WWjhMxCb"
      },
      "outputs": [],
      "source": [
        "sameConvs = set()\n",
        "speakerDuplicates = 0\n",
        "for speaker in speakersMapCount.items():\n",
        "  if len(speaker[1]) > 1:\n",
        "    sameConvs.add((speaker[1][0], speaker[1][1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaWfzkuKYjy8",
        "outputId": "d9ac49ac-dbca-41af-e394-c1f505258913"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "set()"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "sameConvs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7H0egW7A2TV",
        "outputId": "adaeff67-cfa0-4a50-e653-9281c55c25a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ],
      "source": [
        "# Variables to compute a random baseline classifier\n",
        "randomLabel = False\n",
        "\n",
        "ratioOfNonDeltaInTheDataset = 0.9873\n",
        "ratioOfDeltaInTheDataset = 0.0127\n",
        "labelTypes = [0,1]\n",
        "\n",
        "# Split the dataset into train, validation, and test sets\n",
        "train_size = int(0.7 * len(data_list))\n",
        "val_size = int(0.2 * len(data_list))\n",
        "test_size = len(data_list) - train_size - val_size\n",
        "if randomLabel == True:\n",
        "  for data in data_list:\n",
        "    lengthOfLabelsArray = len(data.y)\n",
        "    randomLabels = random.choices(labelTypes, weights = [ratioOfNonDeltaInTheDataset,ratioOfDeltaInTheDataset], k = lengthOfLabelsArray)\n",
        "    randomLabelsRensor = torch.Tensor(randomLabels)\n",
        "    data.y = randomLabelsRensor.long()\n",
        "\n",
        "train_data = data_list[:train_size]\n",
        "val_data = data_list[train_size:train_size+val_size]\n",
        "test_data = data_list[train_size+val_size:]\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "G4YCRBzwNXVB"
      },
      "outputs": [],
      "source": [
        "#train_data[1].edge_attr.size(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgYJ-ufDhQwP",
        "outputId": "8d683174-b105-4e09-b5fb-3352d7b60e11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nodes features dimensionality: 522\n",
            "device is: cpu\n",
            "2135\n"
          ]
        }
      ],
      "source": [
        "def modelSupportsEdgeAttributes(model):\n",
        "  modelName = type(model).__name__\n",
        "  if modelName == 'SplineNN' or modelName == 'DeeperGCN':\n",
        "    return True\n",
        "\n",
        "  return False\n",
        "\n",
        "# Step 2: Train, Test, and Validate a GCN with the constructed dataset\n",
        "# Create the model instance\n",
        "\n",
        "dimensionalityOfNodeFeatures = 0\n",
        "nodeFeaturesFunctionNames = [f.__name__ for f in nodeFeaturesFunctions]\n",
        "for f_name in nodeFeaturesFunctionNames:\n",
        "  dimensionalityOfNodeFeatures += dimensionalityMap[f_name]\n",
        "\n",
        "print('nodes features dimensionality: ' + str(dimensionalityOfNodeFeatures))\n",
        "\n",
        "in_channels = dimensionalityOfNodeFeatures  # Define the input feature dimensionality\n",
        "hidden_channels = 80  # Define the dimensionality of hidden layers\n",
        "out_channels = 2  # Two classes: DELTA (1) and NON-DELTA (0) nodes\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('device is: ' + str(device))\n",
        "\n",
        "num_layers = 2\n",
        "\n",
        "#model = GCN(in_channels, hidden_channels, num_layers, out_channels)\n",
        "model = GSAGE(in_channels, hidden_channels, out_channels).to(device)\n",
        "#model = GSAGEv2(in_channels, hidden_channels, out_channels, num_layers)\n",
        "#model = GAT(in_channels, hidden_channels, num_layers, out_channels, dropout = 0.2)\n",
        "#model = Baseline(in_channels, hidden_channels, out_channels).to(device)\n",
        "\n",
        "# MODELS supporting edge attributes\n",
        "\n",
        "dataSample = train_data[0]\n",
        "num_layers_deep = 16\n",
        "#model = DeeperGCN(dataSample, in_channels, hidden_channels, out_channels, num_layers_deep).to(device)\n",
        "\n",
        "#model = SplineNN(in_channels, hidden_channels, out_channels, dim=len(edgeAttributeFunctions)).to(device)\n",
        "\n",
        "# Define the optimizer and loss function\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "print(len(train_data))\n",
        "\n",
        "train_targets = []\n",
        "for data in train_data:\n",
        "  data = data.to(device)\n",
        "  train_targets.extend(data.y.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "_drmLkTUwjDc"
      },
      "outputs": [],
      "source": [
        "def updateSpeakerMapToLabel(data, speakersMapToLabel, probabilities, predicted_labels):\n",
        "  i = 0\n",
        "  for uttSpeakers in data.utterances_speakers:\n",
        "    for speaker in uttSpeakers:\n",
        "      if speaker not in speakersMapToLabel:\n",
        "        speakersMapToLabel[speaker] = {\n",
        "            \"probabilities\": [],\n",
        "            \"predictions\": [],\n",
        "            \"ground_truths\": [],\n",
        "            \"speaker_label\": 0,\n",
        "            \"probabilities_avg\": {\n",
        "                \"0\": 0,\n",
        "                \"1\": 0\n",
        "            }\n",
        "        }\n",
        "\n",
        "      ground_truth = data.y[i].tolist()\n",
        "      speakersMapToLabel[speaker]['probabilities'].append(probabilities[i].tolist())\n",
        "      speakersMapToLabel[speaker]['predictions'].append(predicted_labels[i].tolist())\n",
        "      speakersMapToLabel[speaker]['ground_truths'].append(ground_truth)\n",
        "\n",
        "      if ground_truth == 1:\n",
        "        speakersMapToLabel[speaker]['speaker_label'] = 1\n",
        "\n",
        "      i += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBLsfdIRvdS5",
        "outputId": "fccab11e-dbf1-4835-c6c1-b04d32b25018"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1\n",
            "Epoch: 2\n",
            "Epoch: 3\n",
            "Epoch: 4\n",
            "Epoch: 5\n",
            "Epoch: 6\n",
            "Epoch: 7\n",
            "Epoch: 8\n",
            "Epoch: 9\n",
            "Epoch: 10\n",
            "Epoch: 11\n",
            "Epoch: 12\n",
            "Epoch: 13\n",
            "Epoch: 14\n",
            "Epoch: 15\n",
            "Epoch: 16\n",
            "Epoch: 17\n",
            "Epoch: 18\n",
            "Epoch: 19\n",
            "Epoch: 20\n",
            "\n",
            "train_targets\n",
            "{0: 174689, 1: 3714}\n",
            "\n",
            "Validation:\n",
            "Loss: 0.12138206511735916\n",
            "Accuracy: 0.9433182208552198\n",
            "AUC-ROC Score: 0.609930740481443\n",
            "Avg Precision: 0.05159040000757733\n",
            "MRR: 0.0016021481134674677\n",
            "F1 Score: 0.5730648289442507\n",
            "Precision: 0.5571926893600871\n",
            "Recall: 0.609930740481443\n",
            "Ratio of Correct 1s: 0.2603448275862069\n",
            "Ratio of Correct 0s: 0.9595166533766791\n",
            "\n",
            "val_predictions\n",
            "{0: 47787, 1: 2282}\n",
            "val_targets\n",
            "{0: 48909, 1: 1160}\n",
            "\n",
            "Test:\n",
            "Loss: 0.21998129785060883\n",
            "Accuracy: 0.9403296306692867\n",
            "Avg Precision: 0.05933994081097617\n",
            "MRR: 0.0016410614968279738\n",
            "AUC-ROC Score: 0.6299414499028494\n",
            "F1 Score: 0.5810389656139533\n",
            "Precision: 0.5620965487379289\n",
            "Recall: 0.6299414499028494\n",
            "Ratio of Correct 1s: 0.30427350427350425\n",
            "Ratio of Correct 0s: 0.9556093955321945\n",
            "\n",
            "test_predictions\n",
            "{0: 23678, 1: 1259}\n",
            "test_targets\n",
            "{0: 24352, 1: 585}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def isLastEpoch(numEpochs, currentEpoch):\n",
        "  return currentEpoch + 1 == numEpochs\n",
        "\n",
        "def getMRR(y_true, y_pred):\n",
        "  # Sort the predictions and get the indices that would sort them in descending order\n",
        "  sorted_indices = torch.argsort(y_pred, descending=True)\n",
        "\n",
        "  # Initialize an empty list to store reciprocal ranks\n",
        "  reciprocal_ranks = []\n",
        "\n",
        "  # Calculate the reciprocal rank for each correct prediction\n",
        "  for i in range(len(y_true)):\n",
        "      if y_true[sorted_indices[i]] == 1:\n",
        "          reciprocal_rank = 1 / (i + 1)  # Add 1 because indices are 0-based\n",
        "          reciprocal_ranks.append(reciprocal_rank)\n",
        "\n",
        "  # Calculate the Mean Reciprocal Rank\n",
        "  if len(reciprocal_ranks) > 0:\n",
        "      return sum(reciprocal_ranks) / len(reciprocal_ranks)\n",
        "  else:\n",
        "      return 0.0\n",
        "\n",
        "# set the number of epochs\n",
        "#num_epochs = 60\n",
        "#num_epochs = 30\n",
        "num_epochs = 20\n",
        "\n",
        "# Initialize lists to store losses\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "\n",
        "speakersMapToTrain = {}\n",
        "speakersMapToLabel = {}\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = compute_class_weight('balanced', classes=[0, 1], y=train_targets)\n",
        "\n",
        "# Convert class weights to a PyTorch tensor\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "\n",
        "# Training loop\n",
        "model.train()\n",
        "\n",
        "printed = False\n",
        "for epoch in range(num_epochs):\n",
        "  for data in train_loader:\n",
        "      data = data.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      if len(edgeAttributeFunctions) > 0 and modelSupportsEdgeAttributes(model):\n",
        "        out = model(data.x, data.edge_index, data.edge_attr)\n",
        "      else:\n",
        "        out = model(data.x, data.edge_index)\n",
        "\n",
        "      predicted_labels = out.argmax(dim=1)\n",
        "\n",
        "      probabilities = F.softmax(out, dim=1)\n",
        "\n",
        "      # Compute loss\n",
        "      loss = F.cross_entropy(out, data.y, weight=class_weights)\n",
        "      #loss = F.cross_entropy(out, data.y)\n",
        "\n",
        "      # Backpropagation\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "  # Evaluation on validation set\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "      val_predictions = []\n",
        "      val_targets = []\n",
        "\n",
        "      val_correct_1s = 0\n",
        "      val_correct_0s = 0\n",
        "\n",
        "      for data in val_loader:\n",
        "          data = data.to(device)\n",
        "          if len(edgeAttributeFunctions) > 0 and modelSupportsEdgeAttributes(model):\n",
        "            out = model(data.x, data.edge_index, data.edge_attr)\n",
        "          else:\n",
        "            out = model(data.x, data.edge_index)\n",
        "\n",
        "          predicted_labels = out.argmax(dim=1)\n",
        "\n",
        "          probabilities = F.softmax(out, dim=1)\n",
        "\n",
        "          yAsList = data.y.tolist()\n",
        "\n",
        "          if(isLastEpoch and not yAsList.count(1) == 0):\n",
        "            updateSpeakerMapToLabel(data, speakersMapToLabel, probabilities, predicted_labels)\n",
        "\n",
        "          val_predictions.extend(predicted_labels.tolist())\n",
        "\n",
        "          val_targets.extend(yAsList)\n",
        "\n",
        "          val_correct_1s += ((predicted_labels == 1) & (data.y == 1)).sum().item()\n",
        "          val_correct_0s += ((predicted_labels == 0) & (data.y == 0)).sum().item()\n",
        "\n",
        "\n",
        "      val_predictions = torch.tensor(val_predictions, dtype=torch.long)\n",
        "      val_targets = torch.tensor(val_targets, dtype=torch.long)\n",
        "\n",
        "      val_loss = F.cross_entropy(out, data.y)\n",
        "      val_accuracy = accuracy_score(val_targets, val_predictions)\n",
        "      val_roc_auc = roc_auc_score(val_targets, val_predictions)\n",
        "      val_avg_precision = average_precision_score(val_targets, val_predictions)\n",
        "      val_mrr = getMRR(val_targets, val_predictions)\n",
        "      val_f1 = f1_score(val_targets, val_predictions, average='macro')\n",
        "      val_precision = precision_score(val_targets, val_predictions, average='macro')\n",
        "      val_recall = recall_score(val_targets, val_predictions, average='macro')\n",
        "\n",
        "      val_ratio_1s = val_correct_1s / (val_targets == 1).sum().item()\n",
        "      val_ratio_0s = val_correct_0s / (val_targets == 0).sum().item()\n",
        "\n",
        "  # Evaluation on test set\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "      test_predictions = []\n",
        "      test_targets = []\n",
        "      test_correct_1s = 0\n",
        "      test_correct_0s = 0\n",
        "\n",
        "      for data in test_loader:\n",
        "          data = data.to(device)\n",
        "          if len(edgeAttributeFunctions) > 0 and modelSupportsEdgeAttributes(model):\n",
        "            out = model(data.x, data.edge_index, data.edge_attr)\n",
        "          else:\n",
        "            out = model(data.x, data.edge_index)\n",
        "          predicted_labels = out.argmax(dim=1)\n",
        "\n",
        "          probabilities = F.softmax(out, dim=1)\n",
        "          yAsList = data.y.tolist()\n",
        "          if(isLastEpoch and not yAsList.count(1) == 0):\n",
        "            updateSpeakerMapToLabel(data, speakersMapToLabel, probabilities, predicted_labels)\n",
        "\n",
        "          test_predictions.extend(predicted_labels.tolist())\n",
        "\n",
        "          test_targets.extend(yAsList)\n",
        "\n",
        "          test_correct_1s += ((predicted_labels == 1) & (data.y == 1)).sum().item()\n",
        "          test_correct_0s += ((predicted_labels == 0) & (data.y == 0)).sum().item()\n",
        "\n",
        "      test_predictions = torch.tensor(test_predictions, dtype=torch.long)\n",
        "      test_targets = torch.tensor(test_targets, dtype=torch.long)\n",
        "\n",
        "      test_loss = F.cross_entropy(out, data.y)\n",
        "      test_accuracy = accuracy_score(test_targets, test_predictions)\n",
        "      test_roc_auc = roc_auc_score(test_targets, test_predictions)\n",
        "      test_avg_precision = average_precision_score(test_targets, test_predictions)\n",
        "      test_mrr = getMRR(test_targets, test_predictions)\n",
        "      test_f1 = f1_score(test_targets, test_predictions, average='macro')\n",
        "      test_precision = precision_score(test_targets, test_predictions, average='macro')\n",
        "      test_recall = recall_score(test_targets, test_predictions, average='macro')\n",
        "      test_ratio_1s = test_correct_1s / (test_targets == 1).sum().item()\n",
        "      test_ratio_0s = test_correct_0s / (test_targets == 0).sum().item()\n",
        "\n",
        "  train_losses.append(loss.item())\n",
        "  test_losses.append(test_loss.item())\n",
        "\n",
        "  print(\"Epoch:\", epoch+1)\n",
        "\n",
        "print('')\n",
        "print('train_targets')\n",
        "trainTargetsArr = np.array(train_targets)\n",
        "trainUnique, trainCount = np.unique(trainTargetsArr, return_counts=True)\n",
        "dictOfTrainCount = dict(zip(trainUnique, trainCount))\n",
        "print(dictOfTrainCount)\n",
        "print('')\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"Validation:\")\n",
        "print(\"Loss:\", val_loss.item())\n",
        "print(\"Accuracy:\", val_accuracy)\n",
        "print(\"AUC-ROC Score:\", val_roc_auc)\n",
        "print(\"Avg Precision:\", val_avg_precision)\n",
        "print(\"MRR:\", val_mrr)\n",
        "print(\"F1 Score:\", val_f1)\n",
        "print(\"Precision:\", val_precision)\n",
        "print(\"Recall:\", val_recall)\n",
        "print(\"Ratio of Correct 1s:\", val_ratio_1s)\n",
        "print(\"Ratio of Correct 0s:\", val_ratio_0s)\n",
        "print('')\n",
        "print('val_predictions')\n",
        "valPredictionArr = val_predictions.numpy()\n",
        "valUniquePred, valCountsPred = np.unique(valPredictionArr, return_counts=True)\n",
        "dictOfValPred = dict(zip(valUniquePred, valCountsPred))\n",
        "print(dictOfValPred)\n",
        "print('val_targets')\n",
        "valTargetsArr = val_targets.numpy()\n",
        "valUniqueTarget, valCountsTarget = np.unique(valTargetsArr, return_counts=True)\n",
        "dictOfValTargets = dict(zip(valUniqueTarget, valCountsTarget))\n",
        "print(dictOfValTargets)\n",
        "print('')\n",
        "\n",
        "print(\"Test:\")\n",
        "print(\"Loss:\", test_loss.item())\n",
        "print(\"Accuracy:\", test_accuracy)\n",
        "print(\"Avg Precision:\", test_avg_precision)\n",
        "print(\"MRR:\", test_mrr)\n",
        "print(\"AUC-ROC Score:\", test_roc_auc)\n",
        "print(\"F1 Score:\", test_f1)\n",
        "print(\"Precision:\", test_precision)\n",
        "print(\"Recall:\", test_recall)\n",
        "print(\"Ratio of Correct 1s:\", test_ratio_1s)\n",
        "print(\"Ratio of Correct 0s:\", test_ratio_0s)\n",
        "print('')\n",
        "\n",
        "print('test_predictions')\n",
        "testPredictionArr = test_predictions.numpy()\n",
        "testUniquePred, testCountsPred = np.unique(testPredictionArr, return_counts=True)\n",
        "dictOfTestPred = dict(zip(testUniquePred, testCountsPred))\n",
        "print(dictOfTestPred)\n",
        "print('test_targets')\n",
        "testTargetsArr = test_targets.numpy()\n",
        "testUniqueTarget, testCountsTarget = np.unique(testTargetsArr, return_counts=True)\n",
        "dictOfTestTarget = dict(zip(testUniqueTarget, testCountsTarget))\n",
        "print(dictOfTestTarget)\n",
        "print('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzNhoRZBI3q9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a690616-992c-4a24-bf89-cdbeb52fd7aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 32821]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "count = 0\n",
        "notInCount = 0\n",
        "for speaker in speakersMapToLabel.items():\n",
        "  if speaker[0] not in speakersMapToTrain:\n",
        "    notInCount += 1\n",
        "  else:\n",
        "    count += 1\n",
        "\n",
        "[count, notInCount]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "faXXtu7hFkeI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a981614d-f810-4d8c-f452-a980f385ea2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC-ROC val: 0.605427135616391\n",
            "AUC-ROC test: 0.6083073960825274\n"
          ]
        }
      ],
      "source": [
        "auc = roc_auc_score(valTargetsArr, valPredictionArr)\n",
        "\n",
        "print(\"AUC-ROC val:\", auc)\n",
        "\n",
        "auc = roc_auc_score(testTargetsArr, testPredictionArr)\n",
        "\n",
        "print(\"AUC-ROC test:\", auc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQnCQDXPr03j"
      },
      "outputs": [],
      "source": [
        "# percentage of nodes that are 1s in the dataset,\n",
        "# a random classifier would therefore classify correctly 1.1% of the nodes\n",
        "#0.01142263759086189"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-N_1iv23atwU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0be55c69-5f8a-4327-83d8-a1345e39e80f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model_name': 'Baseline',\n",
              " 'layers_size': [522, 80, 2],\n",
              " 'pss': 5,\n",
              " 'pds': 0,\n",
              " 'fss': 0,\n",
              " 'fds': 0,\n",
              " 'epochs': 20,\n",
              " 'fetch_mode': ['timestamp'],\n",
              " 'node_features': ['embeddings', 'tf_idf'],\n",
              " 'edge_features': []}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "{\n",
        "    \"model_name\": type(model).__name__, # gets the class name\n",
        "    \"layers_size\": [int(in_channels), int(hidden_channels), int(out_channels)],\n",
        "    \"pss\": int(pss),\n",
        "    \"pds\": int(pds),\n",
        "    \"fss\": int(fss),\n",
        "    \"fds\": int(fds),\n",
        "    \"epochs\": int(num_epochs),\n",
        "    \"fetch_mode\": fetchMode,\n",
        "    \"node_features\": [f.__name__ for f in nodeFeaturesFunctions],\n",
        "    \"edge_features\": [f.__name__ for f in edgeAttributeFunctions],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "y = []\n",
        "opEmbeddings = {}\n",
        "\n",
        "for speaker, attributes in speakersMapToLabel.items():\n",
        "  prob0 = 0\n",
        "  prob1 = 0\n",
        "  probAvg = speakersMapToLabel[speaker]['probabilities_avg']\n",
        "  numOfUtterances = len(attributes['probabilities'])\n",
        "  '''\n",
        "  for probability in attributes['probabilities']:\n",
        "    prob0 += probability[0]\n",
        "    prob1 += probability[1]\n",
        "\n",
        "  probAvg0 = prob0 / numOfUtterances\n",
        "  probAvg1 = prob1 / numOfUtterances\n",
        "  X.append([probAvg0, probAvg1, numOfUtterances])\n",
        "  '''\n",
        "  XtoBeAppended = []\n",
        "  for i in range(5):\n",
        "    try:\n",
        "      XtoBeAppended.append(attributes['probabilities'][i][0])\n",
        "      XtoBeAppended.append(attributes['probabilities'][i][1])\n",
        "    except:\n",
        "      XtoBeAppended.append(0)\n",
        "      XtoBeAppended.append(0)\n",
        "\n",
        "  '''\n",
        "  rightIndex = speaker.rfind('-')\n",
        "  conversationId = speaker[rightIndex + 1: ]\n",
        "  if conversationId not in opEmbeddings:\n",
        "    conversationDfPreprocessed = pd.read_json(preprocessedDatasetDir + conversationId + '.json')\n",
        "    opRow = conversationDfPreprocessed.loc[conversationDfPreprocessed['timestamp'] == 0]\n",
        "    opEmbeddings[conversationId] = opRow['embeddings']\n",
        "\n",
        "  XtoBeAppended = XtoBeAppended + list(opEmbeddings[conversationId])[0]\n",
        "  '''\n",
        "  XtoBeAppended.append(numOfUtterances)\n",
        "\n",
        "\n",
        "  X.append(XtoBeAppended)\n",
        "  y.append(speakersMapToLabel[speaker]['speaker_label'])"
      ],
      "metadata": {
        "id": "in8H6QH6nk-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "id": "wwU9hUz6qnLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X_train),len(X_test),len(y_train),len(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPF2RsEH8Gaz",
        "outputId": "93ad22ed-707f-44e5-d774-328898f5d33d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21990 10831 21990 10831\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#X_test[0]"
      ],
      "metadata": {
        "id": "9NfbFHF59JlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "RSQHnQ62qSAM",
        "outputId": "e1d5ceb0-d2b9-4abf-8fed-5fe73f686a9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_test = rf.predict(X_test)"
      ],
      "metadata": {
        "id": "hCcAlWhyqwdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test, y_pred_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uANTqYbmqy-9",
        "outputId": "640f6707-71ba-4641-9583-31d02a553a22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9555904348628935"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "auc = roc_auc_score(y_test, y_pred_test)\n",
        "print(auc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHUmEnM08nZL",
        "outputId": "ccdd93be-353d-4823-dc65-cfca25973d60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5506918177330652\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ni9FEWrpq4sY",
        "outputId": "6449d51e-b39a-4c0b-bac6-ccdf20f4cef2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98     10319\n",
            "           1       0.71      0.10      0.18       512\n",
            "\n",
            "    accuracy                           0.96     10831\n",
            "   macro avg       0.83      0.55      0.58     10831\n",
            "weighted avg       0.95      0.96      0.94     10831\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmTViQ3fwLwg"
      },
      "outputs": [],
      "source": [
        "if not speakerLevelLabel:\n",
        "  with open(baseDir + 'experiments.json', 'r') as experimentsJson:\n",
        "    experiments = json.load(experimentsJson)\n",
        "    experiments.append({\n",
        "        \"model_name\": type(model).__name__, # gets the class name\n",
        "        \"layers_size\": [int(in_channels), int(hidden_channels), int(out_channels)],\n",
        "        \"pss\": int(pss),\n",
        "        \"pds\": int(pds),\n",
        "        \"fss\": int(fss),\n",
        "        \"fds\": int(fds),\n",
        "        \"epochs\": int(num_epochs),\n",
        "        \"number_of_layers\": num_layers,\n",
        "        \"fetch_mode\": fetchMode,\n",
        "        \"node_features\": [f.__name__ for f in nodeFeaturesFunctions],\n",
        "        \"edge_features\": [f.__name__ for f in edgeAttributeFunctions],\n",
        "        \"with-stopwords\": True,\n",
        "        \"self_edge\": True,\n",
        "        \"val_accuracy\": float(val_accuracy),\n",
        "        \"val_loss\":  float(val_loss.item()),\n",
        "        \"val_f1score\": float(val_f1),\n",
        "        \"val_precision\": float(val_precision),\n",
        "        \"val_recall\": float(val_recall),\n",
        "        \"val_ratio_of_correct_ones\": float(val_ratio_1s),\n",
        "        \"val_ratio_of_correct_zeros\": float(val_ratio_0s),\n",
        "        \"test_accuracy\": float(test_accuracy),\n",
        "        \"test_loss\": float(test_loss.item()),\n",
        "        \"test_f1score\": float(test_f1),\n",
        "        \"test_precision\": float(test_precision),\n",
        "        \"test_recall\": float(test_recall),\n",
        "        \"test_ratio_of_correct_ones\": float(test_ratio_1s),\n",
        "        \"test_ratio_of_correct_zeros\": float(test_ratio_0s),\n",
        "        \"train_size\": str(list(trainCount)),\n",
        "        \"val_size\": str(list(valCountsTarget)),\n",
        "        \"test_size\": str(list(testCountsTarget))\n",
        "    })\n",
        "\n",
        "  with open(baseDir + 'experiments.json', 'w') as experimentsJson:\n",
        "      json.dump(experiments, experimentsJson, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmSPhO2d6Hoi"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "saveSpeakerResults = True\n",
        "\n",
        "# 2.6% is the number of \"persuasive speakers\" a random model would predict\n",
        "if speakerLevelLabel or saveSpeakerResults:\n",
        "  numOfCorrect = numOf1sCorrect + numOf0sCorrect\n",
        "  numOfMisclassified = numOf0sMisclassified + numOf1sMisclassified\n",
        "  valAndTestAccuracy = numOfCorrect / (numOfCorrect + numOfMisclassified)\n",
        "  # trueP / trueP + FalseP\n",
        "  valAndTestPrecision = numOf1sCorrect / (numOf1sCorrect + numOf0sMisclassified)\n",
        "  # TruePositives / (TruePositives + FalseNegatives)\n",
        "  valAndTestRecall = numOf1sCorrect / (numOf1sCorrect + numOf1sMisclassified)\n",
        "  # F-Measure = (2 * Precision * Recall) / (Precision + Recall)\n",
        "  valAndTestF1score = (2 * valAndTestPrecision * valAndTestRecall) / (valAndTestPrecision + valAndTestRecall)\n",
        "\n",
        "  with open(baseDir + 'experiments-speaker-level.json', 'r') as experimentsSpeakerLevelJson:\n",
        "    experimentsSpeakerLevel = json.load(experimentsSpeakerLevelJson)\n",
        "    toBeAppended = {\n",
        "        \"model_name\": type(model).__name__, # gets the class name\n",
        "        \"layers_size\": [int(in_channels), int(hidden_channels), int(out_channels)],\n",
        "        \"pss\": int(pss),\n",
        "        \"pds\": int(pds),\n",
        "        \"fss\": int(fss),\n",
        "        \"fds\": int(fds),\n",
        "        \"epochs\": int(num_epochs),\n",
        "        \"number_of_layers\": num_layers,\n",
        "        \"fetch_mode\": fetchMode,\n",
        "        \"node_features\": [f.__name__ for f in nodeFeaturesFunctions],\n",
        "        \"edge_features\": [f.__name__ for f in edgeAttributeFunctions],\n",
        "        \"persuasive_speaker_comments_labeled_1\": persuasiveSpeakerCommentsLabeledAs1,\n",
        "        \"num_of_1s_correct\": numOf1sCorrect,\n",
        "        \"num_of_1s_misclassified\": numOf1sMisclassified,\n",
        "        \"ratio_of_correct_ones\": numOf1sCorrect / (numOf1sCorrect + numOf1sMisclassified),\n",
        "        \"num_of_0s_correct\": numOf0sCorrect,\n",
        "        \"num_of_0s_misclassified\": numOf0sMisclassified,\n",
        "        \"ratio_of_correct_zeros\": numOf0sCorrect / (numOf0sCorrect + numOf0sMisclassified),\n",
        "        \"num_of_correctly_classified\": numOfCorrect,\n",
        "        \"number_of_misclassified\": numOfMisclassified,\n",
        "        \"val_and_test_accuracy\": float(valAndTestAccuracy),\n",
        "        \"val_and_test_f1score\": float(valAndTestF1score),\n",
        "        \"val_and_test_precision\": float(valAndTestPrecision),\n",
        "        \"val_and_test_recall\": float(valAndTestRecall)\n",
        "    }\n",
        "    experimentsSpeakerLevel.append(toBeAppended)\n",
        "\n",
        "  print(toBeAppended)\n",
        "  #with open(baseDir + 'experiments-speaker-level.json', 'w') as experimentsSpeakerLevelJson:\n",
        "      #json.dump(experimentsSpeakerLevel, experimentsSpeakerLevelJson, indent=4)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "p6Z0mhQLnV3t",
        "outputId": "9abd2e4d-34e8-4c57-b217-93e385958dca"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plot the losses\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(test_losses, label='Test Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLco5PdJHgUI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}